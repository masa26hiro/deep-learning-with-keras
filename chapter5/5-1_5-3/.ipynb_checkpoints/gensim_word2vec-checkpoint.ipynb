{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import os\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\",\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-11 14:06:13,374 : INFO : collecting all words and their counts\n",
      "2020-01-11 14:06:13,389 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-01-11 14:06:13,523 : INFO : PROGRESS: at sentence #10000, processed 500000 words, keeping 33463 word types\n",
      "2020-01-11 14:06:13,661 : INFO : PROGRESS: at sentence #20000, processed 1000000 words, keeping 52754 word types\n",
      "2020-01-11 14:06:13,793 : INFO : PROGRESS: at sentence #30000, processed 1500000 words, keeping 65588 word types\n",
      "2020-01-11 14:06:13,928 : INFO : PROGRESS: at sentence #40000, processed 2000000 words, keeping 78382 word types\n",
      "2020-01-11 14:06:14,068 : INFO : PROGRESS: at sentence #50000, processed 2500000 words, keeping 88007 word types\n",
      "2020-01-11 14:06:14,202 : INFO : PROGRESS: at sentence #60000, processed 3000000 words, keeping 96644 word types\n",
      "2020-01-11 14:06:14,339 : INFO : PROGRESS: at sentence #70000, processed 3500000 words, keeping 104308 word types\n",
      "2020-01-11 14:06:14,485 : INFO : PROGRESS: at sentence #80000, processed 4000000 words, keeping 111460 word types\n",
      "2020-01-11 14:06:14,628 : INFO : PROGRESS: at sentence #90000, processed 4500000 words, keeping 118751 word types\n",
      "2020-01-11 14:06:14,777 : INFO : PROGRESS: at sentence #100000, processed 5000000 words, keeping 125354 word types\n",
      "2020-01-11 14:06:14,919 : INFO : PROGRESS: at sentence #110000, processed 5500000 words, keeping 133140 word types\n",
      "2020-01-11 14:06:15,061 : INFO : PROGRESS: at sentence #120000, processed 6000000 words, keeping 139565 word types\n",
      "2020-01-11 14:06:15,211 : INFO : PROGRESS: at sentence #130000, processed 6500000 words, keeping 145781 word types\n",
      "2020-01-11 14:06:15,348 : INFO : PROGRESS: at sentence #140000, processed 7000000 words, keeping 151933 word types\n",
      "2020-01-11 14:06:15,486 : INFO : PROGRESS: at sentence #150000, processed 7500000 words, keeping 158045 word types\n",
      "2020-01-11 14:06:15,644 : INFO : PROGRESS: at sentence #160000, processed 8000000 words, keeping 164114 word types\n",
      "2020-01-11 14:06:15,780 : INFO : PROGRESS: at sentence #170000, processed 8500000 words, keeping 171255 word types\n",
      "2020-01-11 14:06:15,923 : INFO : PROGRESS: at sentence #180000, processed 9000000 words, keeping 178162 word types\n",
      "2020-01-11 14:06:16,067 : INFO : PROGRESS: at sentence #190000, processed 9500000 words, keeping 184128 word types\n",
      "2020-01-11 14:06:16,203 : INFO : PROGRESS: at sentence #200000, processed 10000000 words, keeping 189074 word types\n",
      "2020-01-11 14:06:16,344 : INFO : PROGRESS: at sentence #210000, processed 10500000 words, keeping 194510 word types\n",
      "2020-01-11 14:06:16,482 : INFO : PROGRESS: at sentence #220000, processed 11000000 words, keeping 198757 word types\n",
      "2020-01-11 14:06:16,620 : INFO : PROGRESS: at sentence #230000, processed 11500000 words, keeping 203440 word types\n",
      "2020-01-11 14:06:16,762 : INFO : PROGRESS: at sentence #240000, processed 12000000 words, keeping 207894 word types\n",
      "2020-01-11 14:06:16,898 : INFO : PROGRESS: at sentence #250000, processed 12500000 words, keeping 212667 word types\n",
      "2020-01-11 14:06:17,040 : INFO : PROGRESS: at sentence #260000, processed 13000000 words, keeping 217127 word types\n",
      "2020-01-11 14:06:17,186 : INFO : PROGRESS: at sentence #270000, processed 13500000 words, keeping 221415 word types\n",
      "2020-01-11 14:06:17,326 : INFO : PROGRESS: at sentence #280000, processed 14000000 words, keeping 226854 word types\n",
      "2020-01-11 14:06:17,460 : INFO : PROGRESS: at sentence #290000, processed 14500000 words, keeping 231423 word types\n",
      "2020-01-11 14:06:17,605 : INFO : PROGRESS: at sentence #300000, processed 15000000 words, keeping 237390 word types\n",
      "2020-01-11 14:06:17,749 : INFO : PROGRESS: at sentence #310000, processed 15500000 words, keeping 241696 word types\n",
      "2020-01-11 14:06:17,885 : INFO : PROGRESS: at sentence #320000, processed 16000000 words, keeping 245648 word types\n",
      "2020-01-11 14:06:18,040 : INFO : PROGRESS: at sentence #330000, processed 16500000 words, keeping 249620 word types\n",
      "2020-01-11 14:06:18,189 : INFO : PROGRESS: at sentence #340000, processed 17000000 words, keeping 253833 word types\n",
      "2020-01-11 14:06:18,191 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 340105 sentences\n",
      "2020-01-11 14:06:18,192 : INFO : Loading a fresh vocabulary\n",
      "2020-01-11 14:06:18,316 : INFO : effective_min_count=30 retains 25097 unique words (9% of original 253854, drops 228757)\n",
      "2020-01-11 14:06:18,317 : INFO : effective_min_count=30 leaves 16191060 word corpus (95% of original 17005207, drops 814147)\n",
      "2020-01-11 14:06:18,380 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2020-01-11 14:06:18,388 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-01-11 14:06:18,388 : INFO : downsampling leaves estimated 11928484 word corpus (73.7% of prior 16191060)\n",
      "2020-01-11 14:06:18,449 : INFO : estimated required memory for 25097 words and 300 dimensions: 72781300 bytes\n",
      "2020-01-11 14:06:18,450 : INFO : resetting layer weights\n",
      "2020-01-11 14:06:22,212 : INFO : training model with 3 workers on 25097 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-01-11 14:06:23,214 : INFO : EPOCH 1 - PROGRESS: at 8.82% examples, 1042173 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:24,214 : INFO : EPOCH 1 - PROGRESS: at 17.82% examples, 1056096 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:06:25,222 : INFO : EPOCH 1 - PROGRESS: at 26.76% examples, 1059417 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:26,224 : INFO : EPOCH 1 - PROGRESS: at 35.52% examples, 1058177 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:27,231 : INFO : EPOCH 1 - PROGRESS: at 44.22% examples, 1053286 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:28,232 : INFO : EPOCH 1 - PROGRESS: at 53.04% examples, 1053763 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:29,233 : INFO : EPOCH 1 - PROGRESS: at 62.10% examples, 1057959 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:30,237 : INFO : EPOCH 1 - PROGRESS: at 70.80% examples, 1055469 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:31,240 : INFO : EPOCH 1 - PROGRESS: at 79.21% examples, 1047708 words/s, in_qsize 4, out_qsize 0\n",
      "2020-01-11 14:06:32,246 : INFO : EPOCH 1 - PROGRESS: at 87.86% examples, 1044963 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:33,249 : INFO : EPOCH 1 - PROGRESS: at 96.32% examples, 1041269 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:33,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-11 14:06:33,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-11 14:06:33,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-11 14:06:33,650 : INFO : EPOCH - 1 : training on 17005207 raw words (11927667 effective words) took 11.4s, 1042904 effective words/s\n",
      "2020-01-11 14:06:34,653 : INFO : EPOCH 2 - PROGRESS: at 8.35% examples, 986940 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:35,657 : INFO : EPOCH 2 - PROGRESS: at 17.23% examples, 1019111 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:06:36,657 : INFO : EPOCH 2 - PROGRESS: at 25.82% examples, 1022799 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:37,662 : INFO : EPOCH 2 - PROGRESS: at 34.28% examples, 1021086 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:38,663 : INFO : EPOCH 2 - PROGRESS: at 43.05% examples, 1027003 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:39,669 : INFO : EPOCH 2 - PROGRESS: at 51.69% examples, 1027240 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:40,675 : INFO : EPOCH 2 - PROGRESS: at 60.57% examples, 1031413 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:41,678 : INFO : EPOCH 2 - PROGRESS: at 69.27% examples, 1032214 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:42,683 : INFO : EPOCH 2 - PROGRESS: at 78.21% examples, 1034043 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:43,685 : INFO : EPOCH 2 - PROGRESS: at 87.15% examples, 1036587 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:44,686 : INFO : EPOCH 2 - PROGRESS: at 96.03% examples, 1038446 words/s, in_qsize 4, out_qsize 0\n",
      "2020-01-11 14:06:45,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-11 14:06:45,114 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-11 14:06:45,117 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-11 14:06:45,118 : INFO : EPOCH - 2 : training on 17005207 raw words (11928534 effective words) took 11.5s, 1040340 effective words/s\n",
      "2020-01-11 14:06:46,125 : INFO : EPOCH 3 - PROGRESS: at 8.64% examples, 1015888 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:47,132 : INFO : EPOCH 3 - PROGRESS: at 17.52% examples, 1032649 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:48,136 : INFO : EPOCH 3 - PROGRESS: at 26.52% examples, 1046624 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:49,144 : INFO : EPOCH 3 - PROGRESS: at 35.58% examples, 1056300 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:50,147 : INFO : EPOCH 3 - PROGRESS: at 44.63% examples, 1061392 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:51,155 : INFO : EPOCH 3 - PROGRESS: at 52.34% examples, 1036692 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:52,159 : INFO : EPOCH 3 - PROGRESS: at 60.86% examples, 1034144 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:53,159 : INFO : EPOCH 3 - PROGRESS: at 69.68% examples, 1036488 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:54,164 : INFO : EPOCH 3 - PROGRESS: at 78.45% examples, 1035522 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:55,166 : INFO : EPOCH 3 - PROGRESS: at 87.09% examples, 1034473 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:56,173 : INFO : EPOCH 3 - PROGRESS: at 95.68% examples, 1032687 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:06:56,677 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-11 14:06:56,687 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-11 14:06:56,688 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-11 14:06:56,689 : INFO : EPOCH - 3 : training on 17005207 raw words (11926923 effective words) took 11.6s, 1030969 effective words/s\n",
      "2020-01-11 14:06:57,696 : INFO : EPOCH 4 - PROGRESS: at 8.35% examples, 982044 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:06:58,698 : INFO : EPOCH 4 - PROGRESS: at 16.70% examples, 984930 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:06:59,700 : INFO : EPOCH 4 - PROGRESS: at 25.35% examples, 1001586 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:07:00,708 : INFO : EPOCH 4 - PROGRESS: at 34.22% examples, 1017315 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:01,713 : INFO : EPOCH 4 - PROGRESS: at 42.87% examples, 1020253 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:07:02,713 : INFO : EPOCH 4 - PROGRESS: at 51.45% examples, 1021488 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:03,715 : INFO : EPOCH 4 - PROGRESS: at 59.69% examples, 1016329 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:04,723 : INFO : EPOCH 4 - PROGRESS: at 67.39% examples, 1003247 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:05,727 : INFO : EPOCH 4 - PROGRESS: at 75.92% examples, 1003931 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:06,735 : INFO : EPOCH 4 - PROGRESS: at 84.39% examples, 1002923 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:07:07,737 : INFO : EPOCH 4 - PROGRESS: at 93.21% examples, 1006912 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:08,476 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-11 14:07:08,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-11 14:07:08,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-11 14:07:08,481 : INFO : EPOCH - 4 : training on 17005207 raw words (11929065 effective words) took 11.8s, 1011741 effective words/s\n",
      "2020-01-11 14:07:09,486 : INFO : EPOCH 5 - PROGRESS: at 8.82% examples, 1039382 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:10,494 : INFO : EPOCH 5 - PROGRESS: at 17.52% examples, 1032926 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:07:11,495 : INFO : EPOCH 5 - PROGRESS: at 26.52% examples, 1047757 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:12,504 : INFO : EPOCH 5 - PROGRESS: at 35.40% examples, 1051707 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:13,506 : INFO : EPOCH 5 - PROGRESS: at 44.28% examples, 1053357 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:07:14,508 : INFO : EPOCH 5 - PROGRESS: at 53.16% examples, 1054739 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:07:15,511 : INFO : EPOCH 5 - PROGRESS: at 61.86% examples, 1052474 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:16,512 : INFO : EPOCH 5 - PROGRESS: at 70.57% examples, 1051109 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:17,513 : INFO : EPOCH 5 - PROGRESS: at 79.39% examples, 1049497 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:18,517 : INFO : EPOCH 5 - PROGRESS: at 88.33% examples, 1050282 words/s, in_qsize 5, out_qsize 0\n",
      "2020-01-11 14:07:19,519 : INFO : EPOCH 5 - PROGRESS: at 97.15% examples, 1049897 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-11 14:07:19,836 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-11 14:07:19,837 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-11 14:07:19,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-11 14:07:19,842 : INFO : EPOCH - 5 : training on 17005207 raw words (11926338 effective words) took 11.4s, 1050013 effective words/s\n",
      "2020-01-11 14:07:19,842 : INFO : training on a 85026035 raw words (59638527 effective words) took 57.6s, 1034848 effective words/s\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(os.path.dirname('__file__'), \"data\")\n",
    "sentences = word2vec.Text8Corpus(os.path.join(DATA_DIR, \"text8\"), 50)\n",
    "model = word2vec.Word2Vec(sentences, size=300, min_count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmasa\\Anaconda3\\envs\\tf-keras\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "2020-01-11 14:08:00,538 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.most_similar('woman')\n",
      "[('girl', 0.7317004203796387), ('child', 0.7103837728500366), ('man', 0.653849720954895), ('lady', 0.6467909812927246), ('herself', 0.6258749961853027), ('prostitute', 0.6251992583274841), ('lover', 0.6177881956100464), ('baby', 0.6101435422897339), ('bride', 0.6062296628952026), ('mother', 0.6046870946884155)]\n",
      "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=10)\n",
      "[('queen', 0.6278002858161926), ('elizabeth', 0.564068078994751), ('empress', 0.5572150349617004), ('prince', 0.5516538619995117), ('princess', 0.5483124256134033), ('throne', 0.5371294021606445), ('isabella', 0.534263551235199), ('daughter', 0.5319634675979614), ('pharaoh', 0.5095462799072266), ('consort', 0.5082883834838867)]\n",
      "model.similarity('girl', 'woman')\n",
      "0.7317005\n",
      "model.similarity('girl', 'man')\n",
      "0.5796545\n",
      "model.similarity('girl', 'car')\n",
      "0.31467545\n",
      "model.similarity('bus', 'car')\n",
      "0.4859891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmasa\\Anaconda3\\envs\\tf-keras\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "C:\\Users\\hmasa\\Anaconda3\\envs\\tf-keras\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\hmasa\\Anaconda3\\envs\\tf-keras\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  del sys.path[0]\n",
      "C:\\Users\\hmasa\\Anaconda3\\envs\\tf-keras\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\hmasa\\Anaconda3\\envs\\tf-keras\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    }
   ],
   "source": [
    "print(\"model.most_similar('woman')\")\n",
    "print(model.most_similar(\"woman\"))\n",
    "\n",
    "\n",
    "print(\"model.most_similar(positive=['woman', 'king'], negative=['man'], topn=10)\")\n",
    "print(model.most_similar(positive=[\"woman\", \"king\"],\n",
    "                         negative=[\"man\"],\n",
    "                         topn=10))\n",
    "\n",
    "print(\"model.similarity('girl', 'woman')\")\n",
    "print(model.similarity(\"girl\", \"woman\"))\n",
    "print(\"model.similarity('girl', 'man')\")\n",
    "print(model.similarity(\"girl\", \"man\"))\n",
    "print(\"model.similarity('girl', 'car')\")\n",
    "print(model.similarity(\"girl\", \"car\"))\n",
    "print(\"model.similarity('bus', 'car')\")\n",
    "print(model.similarity(\"bus\", \"car\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
