{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5jtBRWj-eOk",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 4\n",
        "\n",
        "WavenetのネットワークはResidual Blockを繰り返すように構築されている"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHw-j8VA-aIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Residual Block\n",
        "def residual_block(x):\n",
        "    # 入力そのもの\n",
        "    original_x = x\n",
        "    # Dilated Convolution の結果を活性化関数（tanh）にかける\n",
        "    tanh_out = CausalAtrousConvolution1D(nb_filters, 2, dilation_rate = 2 ** i, padding = 'valid', causal = True,\n",
        "                                         use_bias=use_use_bias, name='dilated_conv_%d_tanh_s%d' % (2 ** i, s), activation='tanh',\n",
        "                                         kernel_regularizer=l2(res_l2))(x)\n",
        "    # Dilated Convolution の結果を活性化関数（sigmoid）にかける\n",
        "    sigm_out = CasualAtrousConvolution1D(nb_filters, 2, dilation_rate=2 ** i, padding='valid', causal = True,\n",
        "                                         use_bias=use_use_bias, name='dilated_conv_%d_sigm_s%d' % (2 ** i, s), activation='sigmoid',\n",
        "                                         kernel_regularizer=l2(res_l2))(x)\n",
        "    # tanh、sigmoidの結果から要素積をとる\n",
        "    x = layers.Multiply(name='gated_activation_%d_s%d' % (i, s))([tanh_out, sigm_out])\n",
        "    # 1 * 1の畳み込み\n",
        "    res_x = layers.Convolution1D(nb_filters, 1, padding='same', use_bias=use_use_bias, kernel_regularizer=l2(res_l2))(x)\n",
        "    skip_x = layers.Convolution1D(nb_filters, 1, padding='same', use_bias=use_use_bias, kernel_regularizer=l2(res_l2))(x)\n",
        "    # 元の入力との全結合？\n",
        "    res_x = layers.Add()([original_x, res_x])\n",
        "    return res_x, skip_x"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}