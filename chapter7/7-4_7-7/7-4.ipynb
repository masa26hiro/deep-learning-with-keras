{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from collections import Counter\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from keras.layers import Input, add, concatenate, dot\n",
    "from keras.layers.core import Activation, Dense, Dropout, Permute\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bAbI():\n",
    "\n",
    "    def __init__(self, use_10k=True, data_root=\"\", padding=\"PAD\"):\n",
    "        self.url = \"http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\"  # noqa\n",
    "        self.vocab = []\n",
    "        self.story_size = -1\n",
    "        self.question_size = -1\n",
    "        self.data_root = data_root\n",
    "        self.use_10k = use_10k #学習用に10000件のデータを使用\n",
    "        #データファイルは2,3文のストーリーの後にその解答が提示される\n",
    "        # John travelled to the hallway.\n",
    "        # Marry journeyed to the bathroom.\n",
    "        # Where is john? hallway 1\n",
    "        if not self.data_root:\n",
    "            self.data_root = os.path.join(os.path.dirname(\"__file__\"), \"data\")\n",
    "        self.PAD = padding\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    @property\n",
    "    def data_dir(self):\n",
    "        _dir = \"tasks_1-20_v1-2/\"\n",
    "        _dir += \"en-10k\" if self.use_10k else \"en\"\n",
    "        return _dir\n",
    "\n",
    "    def _get_location(self, kind=\"train\"):\n",
    "        file_name = \"qa1_single-supporting-fact_{}.txt\".format(kind.lower())\n",
    "        return self.data_dir + \"/\" + file_name\n",
    "\n",
    "    def download(self):\n",
    "        tar_file = os.path.basename(self.url)\n",
    "        if os.path.exists(os.path.join(self.data_root, self.data_dir)):\n",
    "            return\n",
    "        if not os.path.exists(self.data_root):\n",
    "            os.mkdir(self.data_root)\n",
    "\n",
    "        file_path = os.path.join(self.data_root, tar_file)\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(\"Download the bABI data...\")\n",
    "            urlretrieve(self.url, file_path)\n",
    "        with tarfile.open(file_path, mode=\"r:gz\") as gz:\n",
    "            for kind in [\"train\", \"test\"]:\n",
    "                target = self._get_location(kind)\n",
    "                gz.extract(target, self.data_root)\n",
    "        os.remove(file_path)\n",
    "    \n",
    "    #データを読み出すための処理\n",
    "    def _read_qa(self, kind=\"train\"):\n",
    "        path = os.path.join(self.data_root, self._get_location(kind))\n",
    "        stories, questions, answers = [], [], []\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            story_lines = []\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                index, text = line.split(\" \", 1)\n",
    "                if \"\\t\" in text:\n",
    "                    question, answer, _ = text.split(\"\\t\")\n",
    "                    stories.append(\" \".join(story_lines))\n",
    "                    questions.append(question.strip())\n",
    "                    answers.append(answer.strip())\n",
    "                    story_lines = []\n",
    "                else:\n",
    "                    story_lines.append(text)\n",
    "\n",
    "        return stories, questions, answers\n",
    "    \n",
    "    # 単語辞書の作成(20単語)\n",
    "    def make_vocab(self):\n",
    "        train_s, train_q, train_a = self._read_qa(kind=\"train\")\n",
    "        test_s, test_q, test_a = self._read_qa(kind=\"test\")\n",
    "\n",
    "        all_s = train_s + test_s\n",
    "        all_q = train_q + test_q\n",
    "\n",
    "        # Make vocabulary from all stories and questions\n",
    "        words = []\n",
    "        for s, q in zip(all_s, all_q):\n",
    "            s_words = self.tokenize(s)\n",
    "            if len(s_words) > self.story_size:\n",
    "                self.story_size = len(s_words)\n",
    "\n",
    "            q_words = self.tokenize(q)\n",
    "            if len(q_words) > self.question_size:\n",
    "                self.question_size = len(q_words)\n",
    "\n",
    "            words += s_words\n",
    "            words += q_words\n",
    "\n",
    "        word_count = Counter(words)\n",
    "        words = [w_c[0] for w_c in word_count.most_common()]\n",
    "        words.insert(0, self.PAD)  # add pad\n",
    "        self.vocab = words\n",
    "\n",
    "    def tokenize(self, string):\n",
    "        words = text_to_word_sequence(string, lower=True)\n",
    "        return words\n",
    "    \n",
    "    # RNNをベースにしているため入力データは一定の長さの数値列である必要がある\n",
    "    # ストーリーは最大長にそろえて、足りない分はパディング\n",
    "    def get_batch(self, kind=\"train\"):\n",
    "        if self.vocab_size == 0:\n",
    "            self.make_vocab()\n",
    "        stories, questions, answers = self._read_qa(kind)\n",
    "        s_indices = [self.to_indices(s, self.story_size) for s in stories]\n",
    "        q_indices = [self.to_indices(q, self.question_size)\n",
    "                     for q in questions]\n",
    "        a_indices = [self.vocab.index(a) for a in answers]\n",
    "        a_categorical = to_categorical(a_indices, num_classes=self.vocab_size)\n",
    "\n",
    "        return np.array(s_indices), np.array(q_indices), a_categorical\n",
    "\n",
    "    def to_indices(self, string, fit_length=-1):\n",
    "        if self.vocab_size == 0:\n",
    "            raise Exception(\"You have to execute make_vocab\")\n",
    "        words = self.tokenize(string)\n",
    "        indices = [self.vocab.index(w) for w in words]\n",
    "        if fit_length > 0:\n",
    "            indices = indices[:fit_length]\n",
    "            pad_size = fit_length - len(indices)\n",
    "            if pad_size > 0:\n",
    "                indices += [self.vocab.index(self.PAD)] * pad_size\n",
    "        return indices\n",
    "    \n",
    "    # 数値列を単語列に戻すための処理\n",
    "    def to_string(self, indices):\n",
    "        words = [self.vocab[i] for i in indices]\n",
    "        string = \" \".join([w for w in words if w != self.PAD])\n",
    "        return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(story_size, question_size, vocab_size,\n",
    "               embedding_size=64, latent_size=32, drop_rate=0.3):\n",
    "    story_input = Input(shape=(story_size,))\n",
    "    question_input = Input(shape=(question_size,))\n",
    "\n",
    "    story_embed_for_a = Embedding(\n",
    "                        input_dim=vocab_size,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=story_size)\n",
    "    question_embed = Embedding(\n",
    "                        input_dim=vocab_size,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=question_size)\n",
    "    #ストーリと質問の2つを入力として受け取る\n",
    "    #各単語は数値で表現されているためEmbedding層を使用して一定長の単語ベクトルへ変換\n",
    "    story_encoder_for_a = Dropout(drop_rate)(story_embed_for_a(story_input))\n",
    "    question_encoder = Dropout(drop_rate)(question_embed(question_input))\n",
    "\n",
    "    # match story & question along seq_size to make attention on story\n",
    "    # (axes=[batch, seq_size, embed_size] after encoding)\n",
    "    # 変換された質問とストーリの内積をとって関連ベクトルを算出\n",
    "    match = dot([story_encoder_for_a, question_encoder], axes=[2, 2])\n",
    "    \n",
    "    # ストーリを別のベクトル表現に変換\n",
    "    story_embed_for_c = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=question_size,\n",
    "        input_length=story_size\n",
    "    )\n",
    "    story_encoder_for_c = Dropout(drop_rate)(story_embed_for_c(story_input))\n",
    "\n",
    "    # merge match and story context\n",
    "    # 関連ベクトルとマージすることで回答用の情報を作成する\n",
    "    response = add([match, story_encoder_for_c])\n",
    "    # (question_size x story_size) => (story_size x question_size)\n",
    "    response = Permute((2, 1))(response)\n",
    "\n",
    "    answer = concatenate([response, question_encoder], axis=-1)\n",
    "    #回答用の情報を質問と結合し、LSTMに入力\n",
    "    answer = LSTM(latent_size)(answer)\n",
    "    answer = Dropout(drop_rate)(answer)\n",
    "    answer = Dense(vocab_size)(answer)\n",
    "    output = Activation(\"softmax\")(answer)\n",
    "    model = Model(inputs=[story_input, question_input], outputs=output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(batch_size, epochs, show_result_count):\n",
    "    log_dir = os.path.join(os.path.dirname(\"__file__\"), \"logs\")\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "    corpus = bAbI()\n",
    "    corpus.download()\n",
    "    corpus.make_vocab()\n",
    "    train_s, train_q, train_a = corpus.get_batch(kind=\"train\")\n",
    "    test_s, test_q, test_a = corpus.get_batch(kind=\"test\")\n",
    "    print(\"{} train data, {} test data.\".format(len(train_s), len(test_s)))\n",
    "    print(\"vocab size is {}.\".format(corpus.vocab_size))\n",
    "    # 使用単語\n",
    "    print(\"vocab:{}\".format(corpus.vocab))\n",
    "    # データ例\n",
    "    print(\"Story:{}\".format(train_s[0]))\n",
    "    print(\"Story:{}\".format(corpus.to_string(train_s[0])))\n",
    "    print(\"Question:{}\".format(train_q[0]))\n",
    "    print(\"Question:{}\".format(corpus.to_string(train_q[0])))\n",
    "    print(\"Answer:{}\".format(train_a[0]))\n",
    "          \n",
    "    model = make_model(\n",
    "                corpus.story_size, corpus.question_size, corpus.vocab_size)\n",
    "\n",
    "    # train the model\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.fit([train_s, train_q], [train_a],\n",
    "              validation_data=([test_s, test_q], [test_a]),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              callbacks=[TensorBoard(log_dir=log_dir)]\n",
    "              )\n",
    "\n",
    "    answer = np.argmax(test_a, axis=1)\n",
    "    predicted = model.predict([test_s, test_q])\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "\n",
    "    for i in range(show_result_count):\n",
    "        story = corpus.to_string(test_s[i].tolist())\n",
    "        question = corpus.to_string(test_q[i].tolist())\n",
    "        a = corpus.to_string([answer[i]])\n",
    "        p = corpus.to_string([predicted[i]])\n",
    "        ox = \"o\" if a == p else \"x\"\n",
    "        print(story + \"\\n\", question + \"\\n\",\n",
    "              \"{} True: {}, Predicted: {}\".format(ox, a, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 train data, 1000 test data.\n",
      "vocab size is 20.\n",
      "vocab:['PAD', 'to', 'the', 'where', 'is', 'went', 'john', 'sandra', 'mary', 'daniel', 'journeyed', 'travelled', 'back', 'moved', 'bathroom', 'kitchen', 'office', 'hallway', 'garden', 'bedroom']\n",
      "Story:[ 8 13  1  2 14  6  5  1  2 17  0  0]\n",
      "Story:mary moved to the bathroom john went to the hallway\n",
      "Question:[3 4 8]\n",
      "Question:where is mary\n",
      "Answer:[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 2s 151us/step - loss: 2.0505 - accuracy: 0.1777 - val_loss: 1.7696 - val_accuracy: 0.2370\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.7332 - accuracy: 0.2281 - val_loss: 1.6619 - val_accuracy: 0.2460\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.6755 - accuracy: 0.2404 - val_loss: 1.6610 - val_accuracy: 0.2570\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.6592 - accuracy: 0.2464 - val_loss: 1.6545 - val_accuracy: 0.1900\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.6446 - accuracy: 0.2618 - val_loss: 1.6436 - val_accuracy: 0.2600\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.6214 - accuracy: 0.2863 - val_loss: 1.6077 - val_accuracy: 0.3430\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 1.5859 - accuracy: 0.3268 - val_loss: 1.5635 - val_accuracy: 0.3570\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 1s 89us/step - loss: 1.5557 - accuracy: 0.3626 - val_loss: 1.5289 - val_accuracy: 0.4040\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 1s 92us/step - loss: 1.5237 - accuracy: 0.4041 - val_loss: 1.4987 - val_accuracy: 0.4340\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 1.4921 - accuracy: 0.4406 - val_loss: 1.4729 - val_accuracy: 0.4560\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.4579 - accuracy: 0.4726 - val_loss: 1.4200 - val_accuracy: 0.5070\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.4171 - accuracy: 0.4941 - val_loss: 1.3764 - val_accuracy: 0.5110\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 1.3718 - accuracy: 0.5091 - val_loss: 1.3483 - val_accuracy: 0.5150\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.3512 - accuracy: 0.5130 - val_loss: 1.3388 - val_accuracy: 0.5090\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.3437 - accuracy: 0.5128 - val_loss: 1.3224 - val_accuracy: 0.5230\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.3320 - accuracy: 0.5160 - val_loss: 1.3134 - val_accuracy: 0.5170\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 1.3211 - accuracy: 0.51 - 1s 87us/step - loss: 1.3222 - accuracy: 0.5163 - val_loss: 1.3041 - val_accuracy: 0.5140\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.3185 - accuracy: 0.5152 - val_loss: 1.3038 - val_accuracy: 0.4920\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.3067 - accuracy: 0.5149 - val_loss: 1.3003 - val_accuracy: 0.5120\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.2943 - accuracy: 0.5227 - val_loss: 1.2928 - val_accuracy: 0.5120\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.2901 - accuracy: 0.5198 - val_loss: 1.2945 - val_accuracy: 0.5080\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 1.2763 - accuracy: 0.5248 - val_loss: 1.2864 - val_accuracy: 0.5070\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.2729 - accuracy: 0.5266 - val_loss: 1.2552 - val_accuracy: 0.5210\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 1.2327 - accuracy: 0.5441 - val_loss: 1.2004 - val_accuracy: 0.5520\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.1615 - accuracy: 0.5793 - val_loss: 1.0790 - val_accuracy: 0.6170\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 1.0299 - accuracy: 0.6466 - val_loss: 0.9127 - val_accuracy: 0.6990\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.8883 - accuracy: 0.7008 - val_loss: 0.7684 - val_accuracy: 0.7330\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.7767 - accuracy: 0.7305 - val_loss: 0.6854 - val_accuracy: 0.7490\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.6965 - accuracy: 0.7508 - val_loss: 0.6303 - val_accuracy: 0.7520\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.6365 - accuracy: 0.7638 - val_loss: 0.5911 - val_accuracy: 0.7540\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.5970 - accuracy: 0.7702 - val_loss: 0.5692 - val_accuracy: 0.7560\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.5706 - accuracy: 0.7725 - val_loss: 0.5559 - val_accuracy: 0.7510\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.5509 - accuracy: 0.7754 - val_loss: 0.5438 - val_accuracy: 0.7560\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.5337 - accuracy: 0.7813 - val_loss: 0.5393 - val_accuracy: 0.7590\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.5206 - accuracy: 0.7818 - val_loss: 0.5348 - val_accuracy: 0.7600\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.5107 - accuracy: 0.7823 - val_loss: 0.5326 - val_accuracy: 0.7610\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.5039 - accuracy: 0.7839 - val_loss: 0.5294 - val_accuracy: 0.7600\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 1s 89us/step - loss: 0.5027 - accuracy: 0.7822 - val_loss: 0.5277 - val_accuracy: 0.7590\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.4978 - accuracy: 0.7855 - val_loss: 0.5264 - val_accuracy: 0.7630\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.4904 - accuracy: 0.7852 - val_loss: 0.5253 - val_accuracy: 0.7610\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.4870 - accuracy: 0.7875 - val_loss: 0.5247 - val_accuracy: 0.7590\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.4879 - accuracy: 0.7863 - val_loss: 0.5250 - val_accuracy: 0.7630\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.4847 - accuracy: 0.7898 - val_loss: 0.5246 - val_accuracy: 0.7620\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.4797 - accuracy: 0.7895 - val_loss: 0.5254 - val_accuracy: 0.7600\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.4824 - accuracy: 0.7881 - val_loss: 0.5254 - val_accuracy: 0.7570\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 0.4811 - accuracy: 0.7880 - val_loss: 0.5259 - val_accuracy: 0.7570\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.4793 - accuracy: 0.7898 - val_loss: 0.5257 - val_accuracy: 0.7570\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.4765 - accuracy: 0.7925 - val_loss: 0.5270 - val_accuracy: 0.7580\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.4781 - accuracy: 0.7862 - val_loss: 0.5255 - val_accuracy: 0.7600\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.4755 - accuracy: 0.7891 - val_loss: 0.5252 - val_accuracy: 0.7570\n",
      "john travelled to the hallway mary journeyed to the bathroom\n",
      " where is john\n",
      " o True: hallway, Predicted: hallway\n",
      "daniel went back to the bathroom john moved to the bedroom\n",
      " where is mary\n",
      " o True: bathroom, Predicted: bathroom\n",
      "john went to the hallway sandra journeyed to the kitchen\n",
      " where is sandra\n",
      " o True: kitchen, Predicted: kitchen\n",
      "sandra travelled to the hallway john went to the garden\n",
      " where is sandra\n",
      " o True: hallway, Predicted: hallway\n",
      "sandra went back to the bathroom sandra moved to the kitchen\n",
      " where is sandra\n",
      " o True: kitchen, Predicted: kitchen\n",
      "sandra travelled to the kitchen sandra travelled to the hallway\n",
      " where is sandra\n",
      " o True: hallway, Predicted: hallway\n",
      "mary went to the bathroom sandra moved to the garden\n",
      " where is sandra\n",
      " o True: garden, Predicted: garden\n",
      "sandra travelled to the office daniel journeyed to the hallway\n",
      " where is daniel\n",
      " o True: hallway, Predicted: hallway\n",
      "daniel journeyed to the office john moved to the hallway\n",
      " where is sandra\n",
      " x True: office, Predicted: garden\n",
      "john travelled to the bathroom john journeyed to the office\n",
      " where is daniel\n",
      " x True: office, Predicted: bathroom\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(batch_size=64, epochs=50, show_result_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
