# 3.3 CIFAR-10の画像認識に挑戦
https://docs.google.com/presentation/d/1hGIaWRIkKch7f7hXArXNl0FMiv_wOBtqPkTJo1A0NY4/edit?usp=sharing
### CIFAR-10
* 60,000件 の32×32ピクセルのRGB画像、10クラス分類のデータセット
## 3.3.1 ネットワークをより深くすることによる改善
* lenetにConv2Dをもう一つ重なる
    * 精度向上を確認
## 3.3.2 Data Augmentationによる改善
### Data Augmentation
* 学習データをより多く用意することで改善を図る
* 手元にある画像に対して加工を行うことで、変化に強いモデルを学習することができる
* 画像変換の例
    * 画像回転（rotate）
    * 縦横に画像を動かす（shift）
    * 拡大縮小（zoom）
    * 左右上下反転（flip）
処理の流れとしては、学習時のミニバッチごとに処理が行われ、学習データとしてモデルに入力される。

画像変換はランダムな処理なため、毎回異なるミニバッチで学習が行われることになる
## 3.3.3 学習したモデルを利用し予測する
### ImageNet
* 1400万の画像に対して2万のクラウスが付与されているデータセット
* ILSVRC-2012のコンペにおいては、130万件の画像に1000クラスのデータセットを使用した
# 3.4 大規模な画像認識のための非常に深いネットワーク

## 3.4.1 組み込みのVGG-16のモデルを使用する
* imageNetで学習を行ったVGG-16のモデルをロードできる
## 3.4.2 学習済みのモデルを特徴抽出器として活用する
* imageNetで学習を行ったVGG-16のモデルをロードし、
途中の層を使って特徴を抽出する
* なぜ中間層を抽出するのか？
    * ネットワークの中間層は、画像の汎用的な特徴量を表現しているため
* 学習済みモデルを用いることで学習時間を削減できるなどのメリットがある
## Inception-v3を使用した転移学習 
### fine tuning
* 異なるタスクに対して、事前学習済みのモデルの一部を使って学習を行う
* fine tuningの流れ
    * 学習済みモデルの全結合部分を学習したいタスクに合わせて変更する
    * 学習済みモデル（Inception v3）の部分はパラメータを固定して、変更した全結合部分のみ学習を行う
    * 数エポック学習後、Inception v3の上位層も学習可能に変更
        * Inception v3部分を目標タスクに微調整するイメージ
### Global AveragePooling
* 通常のpoolingと異なり、チャンネル内すべてで平均をとる
    * つまり、出力は入力時のチャネル数になる
    * Global AveragePoolingにすることで全結合部分の学習パラメータを抑える